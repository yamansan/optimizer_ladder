#!/usr/bin/env python
"""
LIFO PnL Monitor
----------------
Continuously watches a fills CSV (generated by `continuous_fill_monitor.py`),
maintains a LIFO buy stack (price, quantity), and whenever a SELL order is
encountered it calculates realised PnL (and complement PnL if partial on the
first popped buy) using the same formula shown in `LIFO.ipynb`.

A record of each SELL event is appended to an output CSV.

USAGE EXAMPLE
-------------
python lifo_pnl_monitor.py \
       --start-time "2025-07-02 02:00:00" \
       --csv-file data/output/ladder/continuous_fills.csv \
       --output lifo_pnl_results.csv
"""

import argparse
import csv
import os
import pickle
import time
from datetime import datetime
from typing import List, Tuple, Optional

import pandas as pd

PositionStack = List[Tuple[float, float]]  # (quantity, price) - qty>0 for long, qty<0 for short

# ---------------------------------------------------------------------------
# LIFO PnL calculation (using new logic that handles both long and short)
# ---------------------------------------------------------------------------

def calculate_lifo_pnl_and_update_stack(stack: List[Tuple[float, float]], qty: float, price: float) -> float:
    """
    Process a trade using LIFO logic and return realized PnL.
    stack: list of (quantity, price); qty>0 = long, qty<0 = short
    qty: trade quantity (positive for buy, negative for sell)
    price: trade price
    Returns: realized PnL for this trade
    """
    remaining = qty # This is signed quantity. If qty is positive, it is a buy. If qty is negative, it is a sell.
    pnl_this_trade = 0.0

    # 1️⃣ offset against opposite lots
    while remaining and stack and ((remaining > 0) ^ (stack[-1][0] > 0)): # This checks if the last lot has the opposite sign of the remaining quantity.
        lot_qty, lot_price = stack.pop()   # This is the last available lot in the stack.
        match = min(abs(remaining), abs(lot_qty))  # This is the quantity to match. 
                                                   # Match is already non-negative.

        if remaining < 0:        # selling long
            pnl_this_trade += (price - lot_price) * match * 16 * 62.5
        else:                    # buying to cover short
            pnl_this_trade += (lot_price - price) * match * 16 * 62.5

        # shrink lot & remaining
        if abs(lot_qty) > match: # This is the case where the last lot quantity is greater than the match quantity.
            stack.append((lot_qty / abs(lot_qty) * (abs(lot_qty) - match), lot_price)) # This adds the remaining quantity to the stack.
        remaining = remaining / abs(remaining) * (abs(remaining) - match) if remaining != 0 else 0 # This updates the remaining quantity.

    # 2️⃣ leftover becomes a new open lot
    if remaining: # This is the case where the remaining quantity is not zero.
        stack.append((remaining, price)) # This adds the remaining quantity to the stack.

    return pnl_this_trade


# ---------------------------------------------------------------------------
# Helper utilities
# ---------------------------------------------------------------------------

_DT_FORMAT_WITH_MS = "%Y-%m-%d %H:%M:%S.%f"
_DT_FORMAT_NO_MS = "%Y-%m-%d %H:%M:%S"


def parse_fill_datetime(date_str: str, time_str: str) -> datetime:
    """Return datetime constructed from *Date* and *Time* columns."""
    txt = f"{date_str} {time_str}"
    try:
        return datetime.strptime(txt, _DT_FORMAT_WITH_MS)
    except ValueError:
        return datetime.strptime(txt, _DT_FORMAT_NO_MS)

# ---------------------------------------------------------------------------
# Stack persistence functions
# ---------------------------------------------------------------------------

def save_stack_state(stack: PositionStack, last_row: int, processed_txns: set, state_file: str) -> None:
    """Save stack state to disk for persistence across restarts."""
    state = {
        'stack': stack,
        'last_processed_row': last_row,
        'processed_transactions': processed_txns
    }
    with open(state_file, 'wb') as f:
        pickle.dump(state, f)

def load_stack_state(state_file: str) -> Tuple[PositionStack, int, set]:
    """Load stack state from disk. Returns empty state if file doesn't exist."""
    if not os.path.exists(state_file):
        return [], 0, set()
    
    try:
        with open(state_file, 'rb') as f:
            state = pickle.load(f)
        return state['stack'], state['last_processed_row'], state['processed_transactions']
    except Exception as e:
        print(f"Warning: Could not load stack state ({e}). Starting fresh.")
        return [], 0, set()

# ---------------------------------------------------------------------------
# Main loop
# ---------------------------------------------------------------------------

def monitor(csv_path: str, start_dt: datetime, output_path: str, poll: int = 5, max_events: Optional[int] = None) -> None:
    # Load existing stack state or start fresh
    state_file = output_path.replace('.csv', '_state.pkl') # Creating a state file for the stack.
    position_stack, last_processed_row, processed_transactions = load_stack_state(state_file) # Loading the stack from the state file.
    
    print(f"Loaded state: stack_size={len(position_stack)}, last_row={last_processed_row}, processed_txns={len(processed_transactions)}")
    
    # Ensure output CSV has header
    if not os.path.exists(output_path): # If the output file does not exist, create it.
        with open(output_path, "w", newline="") as f:
            csv.writer(f).writerow([
                "Timestamp", "TradeQty", "TradePx", "RealisedPnL", "StackSize"
            ])

    print(f"Monitoring {csv_path} from {start_dt} (poll every {poll}s)…")

    sell_events = 0
    save_counter = 0  # Save state every N iterations
    while True:
        if not os.path.exists(csv_path): 
            print(f"Waiting for {csv_path} …")
            time.sleep(poll)
            continue

        try:
            df = pd.read_csv(csv_path)
        except Exception as exc:
            print(f"Error reading CSV: {exc}")
            time.sleep(poll)
            continue

        # Only process new rows
        if last_processed_row < len(df):
            new_rows = df.iloc[last_processed_row:]
            
            for idx, row in new_rows.iterrows():
                ts = parse_fill_datetime(row["Date"], row["Time"]) # Timestamp of the trade
                if ts < start_dt:
                    continue

                # Filter for specific criteria: CME exchange, Eric user, ZN Sep25 contract
                if (row.get("Exchange", "") != "CME" or 
                    row.get("CurrentUser", "") != "Eric" or 
                    row.get("Contract", "") != "ZN Sep25"):
                    continue
                
                side = int(row["Side"])     # 1 for buy, 2 for sell
                qty = float(row["Quantity"]) # Quantity of the trade
                px = float(row["Price"])     # Price of the trade
                
                # Create unique transaction ID to avoid duplicates
                transaction_id = f"{ts}_{side}_{qty}_{px}_{row.get('OrderId', '')}"
                
                if transaction_id in processed_transactions:
                    continue  # Skip duplicate
                
                processed_transactions.add(transaction_id)

                # Convert side to quantity (positive for buy, negative for sell)
                trade_qty = qty if side == 1 else -qty
                
                try:
                    # Calculate PnL and update stack in one call
                    pnl = calculate_lifo_pnl_and_update_stack(position_stack, trade_qty, px) # Calculating the PnL and updating the stack.
                    
                    # Write to output CSV for all trades (only non-zero PnL trades have realized gains/losses)
                    if pnl != 0:  # Only log trades that realize PnL
                        with open(output_path, "a", newline="") as f:
                            csv.writer(f).writerow([ts, trade_qty, px, pnl, len(position_stack)])
                        print(f"TRADE: {ts} {trade_qty}@{px:.6f} PnL={pnl:.2f} stack={len(position_stack)}")
                        
                        if trade_qty < 0:  # Count sell events for max_events logic
                            sell_events += 1
                            if max_events and sell_events >= max_events:
                                print("Max SELL events processed. Exiting monitor.")
                                save_stack_state(position_stack, last_processed_row, processed_transactions, state_file)
                                return
                    else:
                        print(f"TRADE: {ts} {trade_qty}@{px:.6f} (new position) stack={len(position_stack)}")
                        
                except ValueError as e:
                    print(f"{ts} ERROR: {e}")
                    # Still write error to CSV for tracking
                    with open(output_path, "a", newline="") as f:
                        csv.writer(f).writerow([ts, trade_qty, px, f"ERROR: {e}", len(position_stack)])
            
            last_processed_row = len(df)

        time.sleep(poll)

        # Save state periodically
        save_counter += 1
        if save_counter >= 10:  # Save state every 50 seconds
            save_stack_state(position_stack, last_processed_row, processed_transactions, state_file)
            save_counter = 0

# ---------------------------------------------------------------------------
if __name__ == "__main__":
    ap = argparse.ArgumentParser(description="Continuous LIFO PnL monitor")
    ap.add_argument("--start-time", "-s", required=True, help="YYYY-MM-DD HH:MM:SS")
    ap.add_argument("--csv-file", "-f", default="data/output/ladder/continuous_fills.csv")
    ap.add_argument("--output", "-o", default="lifo_pnl_results.csv")
    ap.add_argument("--interval", "-i", type=int, default=5, help="Polling interval seconds")
    ap.add_argument("--max-events", type=int, help="Process this many SELL events then exit (for testing)")
    ap.add_argument("--reset", action="store_true", help="Reset stack state and start fresh")
    args = ap.parse_args()

    # Reset state if requested
    if args.reset:
        state_file = args.output.replace('.csv', '_state.pkl')
        if os.path.exists(state_file):
            os.remove(state_file)
            print("Stack state reset. Starting fresh.")

    start_time_dt = datetime.strptime(args.start_time, "%Y-%m-%d %H:%M:%S")

    monitor(args.csv_file, start_time_dt, args.output, args.interval, args.max_events) 